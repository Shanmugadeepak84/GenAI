{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1ALdqDzR5Sjf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ALdqDzR5Sjf",
        "outputId": "dfc4f49a-c9dd-4166-be8e-e9ff29eb52f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "o6XYqjCrZe3p",
      "metadata": {
        "id": "o6XYqjCrZe3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe34827c-fba2-4cdf-c60f-e913dd6c7455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a1e6d874-ea96-4a4d-9fb7-2ba31f3e2f22",
      "metadata": {
        "id": "a1e6d874-ea96-4a4d-9fb7-2ba31f3e2f22"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQTt0jUdEzuR"
      },
      "source": [
        "#Task-1:Stopwords Removal: Implement stopwords removal using N- LTK."
      ],
      "id": "qQTt0jUdEzuR"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "nlLNr_wi-O75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlLNr_wi-O75",
        "outputId": "13e50f76-7b43-4d37-cec6-214308a3840c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fe5036ca-cd53-4f07-b592-cdf52d86a874",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe5036ca-cd53-4f07-b592-cdf52d86a874",
        "outputId": "96e5630c-a034-4b94-89d0-bf89f6b385e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dcf57618-d1ee-46b8-a80a-1063e3dc4551",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcf57618-d1ee-46b8-a80a-1063e3dc4551",
        "outputId": "fd816851-a727-4015-8bfa-bd9bf577728c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text:  Christopher Nolan’s Inception is a mind-bending journey through the layers of dreams and reality. With a gripping plot, stunning visuals, and a stellar cast led by Leonardo DiCaprio, this film challenges the audience to question the very nature of consciousness.\n"
          ]
        }
      ],
      "source": [
        "text=\"Christopher Nolan’s Inception is a mind-bending journey through the layers of dreams and reality. With a gripping plot, stunning visuals, and a stellar cast led by Leonardo DiCaprio, this film challenges the audience to question the very nature of consciousness.\"\n",
        "print(\"Sample Text: \", text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "wX6jU5zzhMS8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX6jU5zzhMS8",
        "outputId": "38524a0b-fe35-4b0a-a348-170ed9605401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"won't\", \"she'll\", 'because', 'has', 'won', 'y', 'further', 'which', 'couldn', 'its', 'to', 'a', 'few', 'hasn', 'both', 'yourselves', 'above', \"she's\", 'yours', 'myself', 'have', 'wouldn', \"they'd\", \"couldn't\", 'yourself', 'ourselves', 't', 'by', 'until', 'haven', 'the', 'her', 'his', \"should've\", 'don', 'wasn', 'all', 'most', \"shan't\", \"he'll\", 'they', 'and', \"weren't\", 'm', 'into', 'on', 'll', \"he'd\", 'more', 'before', 'whom', 'during', 'against', \"wasn't\", 'i', 'an', 'how', 'mustn', 'been', \"it'll\", 'them', 'why', \"don't\", 'is', \"shouldn't\", 'through', 'he', 'when', 'our', 'not', 'o', 'be', 'herself', 'it', 'didn', 'there', 'having', 'over', 'now', 'do', \"didn't\", 'where', 'no', 'd', \"you're\", 'as', \"we'd\", 'needn', 'very', 'shouldn', 'from', \"it's\", 'this', 'up', 'about', 'doesn', 'then', \"i'm\", 'such', 'am', \"i'd\", 'again', 'between', 'were', 'with', \"mustn't\", 've', \"mightn't\", 'here', 'for', \"we'll\", 'ain', 'in', 'weren', \"you've\", 'out', 'off', \"needn't\", 'some', 'you', \"aren't\", 'mightn', \"isn't\", 'your', \"it'd\", 'my', 'will', 'any', 'while', 'each', \"doesn't\", 's', 'itself', 'themselves', 'we', 'than', 'me', 'just', 'at', 'those', 'after', 'too', 'ma', 'who', 'him', 'being', 'are', 'once', 'or', 'was', 'below', 'other', \"we're\", 'of', 'should', 'ours', 'doing', 'these', \"you'll\", 'himself', 'theirs', 'own', 're', 'shan', 'under', \"i'll\", 'so', \"hadn't\", 'if', 'isn', \"they'll\", \"you'd\", 'hers', 'what', 'did', 'she', 'had', 'that', 'nor', 'does', \"i've\", \"haven't\", 'hadn', \"hasn't\", 'can', \"they're\", \"that'll\", \"wouldn't\", 'their', \"they've\", 'aren', \"she'd\", \"we've\", 'only', 'same', 'down', \"he's\", 'but'}\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "SCMf8hQ7hN54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCMf8hQ7hN54",
        "outputId": "08afc599-dfa7-4afc-c930-0652a3aefc62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1Fco1aVGnU-y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fco1aVGnU-y",
        "outputId": "4685a145-2dd2-4089-e738-41a7e01e20f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Christopher',\n",
              " 'Nolan',\n",
              " '’',\n",
              " 's',\n",
              " 'Inception',\n",
              " 'is',\n",
              " 'a',\n",
              " 'mind-bending',\n",
              " 'journey',\n",
              " 'through',\n",
              " 'the',\n",
              " 'layers',\n",
              " 'of',\n",
              " 'dreams',\n",
              " 'and',\n",
              " 'reality',\n",
              " '.',\n",
              " 'With',\n",
              " 'a',\n",
              " 'gripping',\n",
              " 'plot',\n",
              " ',',\n",
              " 'stunning',\n",
              " 'visuals',\n",
              " ',',\n",
              " 'and',\n",
              " 'a',\n",
              " 'stellar',\n",
              " 'cast',\n",
              " 'led',\n",
              " 'by',\n",
              " 'Leonardo',\n",
              " 'DiCaprio',\n",
              " ',',\n",
              " 'this',\n",
              " 'film',\n",
              " 'challenges',\n",
              " 'the',\n",
              " 'audience',\n",
              " 'to',\n",
              " 'question',\n",
              " 'the',\n",
              " 'very',\n",
              " 'nature',\n",
              " 'of',\n",
              " 'consciousness',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "mywords = word_tokenize(text)\n",
        "mywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b6d25876-a3b0-47a7-b0f9-5330f38aa684",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6d25876-a3b0-47a7-b0f9-5330f38aa684",
        "outputId": "afa4c745-4aff-4210-e6b9-e33529a3afec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stopwords\n",
            "s\n",
            "is\n",
            "a\n",
            "through\n",
            "the\n",
            "of\n",
            "and\n",
            "With\n",
            "a\n",
            "and\n",
            "a\n",
            "by\n",
            "this\n",
            "the\n",
            "to\n",
            "the\n",
            "very\n",
            "of\n",
            "Original Text:\n",
            "Christopher Nolan’s Inception is a mind-bending journey through the layers of dreams and reality. With a gripping plot, stunning visuals, and a stellar cast led by Leonardo DiCaprio, this film challenges the audience to question the very nature of consciousness.\n",
            "\n",
            "Text after removing stopwords:\n",
            "['s', 'is', 'a', 'through', 'the', 'of', 'and', 'With', 'a', 'and', 'a', 'by', 'this', 'the', 'to', 'the', 'very', 'of']\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Stopwords\n",
        "print(\"\\nStopwords\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_text=[]\n",
        "for word in mywords:\n",
        "    if word.lower() in stop_words:\n",
        "        print(word)\n",
        "        filtered_text.append(word)\n",
        "\n",
        "#filtered_text = [word for word in word_tokenize(text) if word.lower() not in stop_words]\n",
        "print(\"Original Text:\")\n",
        "print(text)\n",
        "print(\"\\nText after removing stopwords:\")\n",
        "print(filtered_text)\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcefb6e-f8d6-41ad-b36a-e1c320d5345a",
      "metadata": {
        "id": "6bcefb6e-f8d6-41ad-b36a-e1c320d5345a"
      },
      "source": [
        "#Task2:Tokenization: Tokenize the given text into words or sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "kfBpzazcFblz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfBpzazcFblz",
        "outputId": "b48da120-fc1e-4564-d5b6-d9c83663e6db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Christopher',\n",
              " 'Nolan’s',\n",
              " 'Inception',\n",
              " 'is',\n",
              " 'a',\n",
              " 'mind-bending',\n",
              " 'journey',\n",
              " 'through',\n",
              " 'the',\n",
              " 'layers',\n",
              " 'of',\n",
              " 'dreams',\n",
              " 'and',\n",
              " 'reality.',\n",
              " 'With',\n",
              " 'a',\n",
              " 'gripping',\n",
              " 'plot,',\n",
              " 'stunning',\n",
              " 'visuals,',\n",
              " 'and',\n",
              " 'a',\n",
              " 'stellar',\n",
              " 'cast',\n",
              " 'led',\n",
              " 'by',\n",
              " 'Leonardo',\n",
              " 'DiCaprio,',\n",
              " 'this',\n",
              " 'film',\n",
              " 'challenges',\n",
              " 'the',\n",
              " 'audience',\n",
              " 'to',\n",
              " 'question',\n",
              " 'the',\n",
              " 'very',\n",
              " 'nature',\n",
              " 'of',\n",
              " 'consciousness.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "list_of_words = text.split(\" \") # word tokenization\n",
        "list_of_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "h3jOCxb4GxYU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3jOCxb4GxYU",
        "outputId": "15d5dc20-7508-4a50-9d9b-b6e74fc25f89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Christopher',\n",
              " 'Nolan’s',\n",
              " 'Inception',\n",
              " 'is',\n",
              " 'a',\n",
              " 'mind-bending',\n",
              " 'journey',\n",
              " 'through',\n",
              " 'the',\n",
              " 'layers',\n",
              " 'of',\n",
              " 'dreams',\n",
              " 'and',\n",
              " 'reality.',\n",
              " 'With',\n",
              " 'a',\n",
              " 'gripping',\n",
              " 'plot,',\n",
              " 'stunning',\n",
              " 'visuals,',\n",
              " 'and',\n",
              " 'a',\n",
              " 'stellar',\n",
              " 'cast',\n",
              " 'led',\n",
              " 'by',\n",
              " 'Leonardo',\n",
              " 'DiCaprio,',\n",
              " 'this',\n",
              " 'film',\n",
              " 'challenges',\n",
              " 'the',\n",
              " 'audience',\n",
              " 'to',\n",
              " 'question',\n",
              " 'the',\n",
              " 'very',\n",
              " 'nature',\n",
              " 'of',\n",
              " 'consciousness.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "list_of_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "FOOy18bwF3XU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOOy18bwF3XU",
        "outputId": "e4214833-f939-4f7b-d925-8f67306d8907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C', 'h', 'r', 'i', 's', 't', 'o', 'p', 'h', 'e', 'r']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "list(list_of_words[0]) # character tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "debe2daa-40bb-447a-ae6d-51b6bc97ea66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "debe2daa-40bb-447a-ae6d-51b6bc97ea66",
        "outputId": "ae385ebc-9bc8-4504-d05b-123c46ab0ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization\n",
            "Original Text:\n",
            "Christopher Nolan’s Inception is a mind-bending journey through the layers of dreams and reality. With a gripping plot, stunning visuals, and a stellar cast led by Leonardo DiCaprio, this film challenges the audience to question the very nature of consciousness.\n",
            "\n",
            "Tokens:\n",
            "['Christopher', 'Nolan', '’', 's', 'Inception', 'is', 'a', 'mind-bending', 'journey', 'through', 'the', 'layers', 'of', 'dreams', 'and', 'reality', '.', 'With', 'a', 'gripping', 'plot', ',', 'stunning', 'visuals', ',', 'and', 'a', 'stellar', 'cast', 'led', 'by', 'Leonardo', 'DiCaprio', ',', 'this', 'film', 'challenges', 'the', 'audience', 'to', 'question', 'the', 'very', 'nature', 'of', 'consciousness', '.']\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "print(\"\\nTokenization\")\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Original Text:\")\n",
        "print(text)\n",
        "print(\"\\nTokens:\")\n",
        "print(tokens)\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54577245-b8ef-45d4-a30d-4748ad877be5",
      "metadata": {
        "id": "54577245-b8ef-45d4-a30d-4748ad877be5"
      },
      "source": [
        "#Task3:Stemming and Lemmatization: Apply stemming and lemmatization on the tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ffcf8622-a516-4519-a46f-0c5489d0923a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffcf8622-a516-4519-a46f-0c5489d0923a",
        "outputId": "57841af2-bb0d-4c76-c111-6f49c76ba7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming\n",
            "s -> s\n",
            "is -> is\n",
            "a -> a\n",
            "through -> through\n",
            "the -> the\n",
            "of -> of\n",
            "and -> and\n",
            "With -> with\n",
            "a -> a\n",
            "and -> and\n",
            "a -> a\n",
            "by -> by\n",
            "this -> thi\n",
            "the -> the\n",
            "to -> to\n",
            "the -> the\n",
            "very -> veri\n",
            "of -> of\n",
            "Original Tokens:\n",
            "['s', 'is', 'a', 'through', 'the', 'of', 'and', 'With', 'a', 'and', 'a', 'by', 'this', 'the', 'to', 'the', 'very', 'of']\n",
            "\n",
            "Stemmed Tokens:\n",
            "['s', 'is', 'a', 'through', 'the', 'of', 'and', 'with', 'a', 'and', 'a', 'by', 'thi', 'the', 'to', 'the', 'veri', 'of']\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Stemming\n",
        "print(\"\\nStemming\")\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words=[]\n",
        "for word in filtered_text:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    stemmed_words.append(stemmed_word)\n",
        "    print(f\"{word} -> {stemmed_word}\")\n",
        "#stemmed_words = [stemmer.stem(word) for word in filtered_text]\n",
        "print(\"Original Tokens:\")\n",
        "print(filtered_text)\n",
        "print(\"\\nStemmed Tokens:\")\n",
        "print(stemmed_words)\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99889584-0d15-4351-ade1-37920455ab24",
      "metadata": {
        "id": "99889584-0d15-4351-ade1-37920455ab24"
      },
      "source": [
        "In below example 'computers' become 'computer'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7fde400e-680d-4d11-8d84-dd31f262e763",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fde400e-680d-4d11-8d84-dd31f262e763",
        "outputId": "54520ea9-1939-49af-fa34-6603bcec67c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lemmatization\n",
            "Original Tokens:\n",
            "['s', 'is', 'a', 'through', 'the', 'of', 'and', 'With', 'a', 'and', 'a', 'by', 'this', 'the', 'to', 'the', 'very', 'of']\n",
            "\n",
            "Lemmatized Tokens:\n",
            "['s', 'is', 'a', 'through', 'the', 'of', 'and', 'With', 'a', 'and', 'a', 'by', 'this', 'the', 'to', 'the', 'very', 'of']\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Lemmatization\n",
        "print(\"\\nLemmatization\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words=[]\n",
        "for word in filtered_text:\n",
        "    lemmatized_word = lemmatizer.lemmatize(word)\n",
        "    lemmatized_words.append(lemmatized_word)\n",
        "#lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_text]\n",
        "print(\"Original Tokens:\")\n",
        "print(filtered_text)\n",
        "print(\"\\nLemmatized Tokens:\")\n",
        "print(lemmatized_words)\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcedce5e-611d-4d35-a3f7-f77d26462547",
      "metadata": {
        "id": "bcedce5e-611d-4d35-a3f7-f77d26462547"
      },
      "source": [
        "# Task4:-POS Tagging: Perform Part-of-Speech tagging on the - tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "rnN1nPqHIeRl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnN1nPqHIeRl",
        "outputId": "faa68b2e-b8dd-44ed-a266-a5924ad7c317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "adfedeb5-6520-4ae1-8994-6f326d006a46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adfedeb5-6520-4ae1-8994-6f326d006a46",
        "outputId": "54029f71-88c5-4ec7-effd-4ae9de9b6027",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POS Tagging\n",
            "Original Tokens:\n",
            "['s', 'is', 'a', 'through', 'the', 'of', 'and', 'With', 'a', 'and', 'a', 'by', 'this', 'the', 'to', 'the', 'very', 'of']\n",
            "\n",
            "POS Tags:\n",
            "[('s', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('through', 'IN'), ('the', 'DT'), ('of', 'IN'), ('and', 'CC'), ('With', 'IN'), ('a', 'DT'), ('and', 'CC'), ('a', 'DT'), ('by', 'IN'), ('this', 'DT'), ('the', 'DT'), ('to', 'TO'), ('the', 'DT'), ('very', 'RB'), ('of', 'IN')]\n",
            "==================================================\n",
            "CPU times: user 776 µs, sys: 0 ns, total: 776 µs\n",
            "Wall time: 773 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\nPOS Tagging\")\n",
        "pos_tags = pos_tag(lemmatized_words)\n",
        "print(\"Original Tokens:\")\n",
        "print(lemmatized_words)\n",
        "print(\"\\nPOS Tags:\")\n",
        "print(pos_tags)\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ShIxv4ffJZFK",
      "metadata": {
        "id": "ShIxv4ffJZFK"
      },
      "outputs": [],
      "source": [
        "import re as re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "g53GyEY0Jax4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g53GyEY0Jax4",
        "outputId": "00d462f4-a4aa-46f0-ab1d-73c6809b1e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s is a through the of and With a and a by this the to the very of\n"
          ]
        }
      ],
      "source": [
        "txt = \" \".join(lemmatized_words)\n",
        "x = re.sub('[^a-zA-Z0-9]', \" \", txt)\n",
        "x = re.sub(\"  \", \" \", x)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af67176e-7277-4ad6-9b8d-de5bf5d3ce95",
      "metadata": {
        "id": "af67176e-7277-4ad6-9b8d-de5bf5d3ce95"
      },
      "source": [
        "# Task5:TF-IDF Vectorization: Convert the preprocessed text into TF-IDF - vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "28Fsh4C2ko_9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "28Fsh4C2ko_9",
        "outputId": "0b5a2210-db26-47b7-f3e9-277195bfc1c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Christopher Nolan’s Inception is a mind-bending journey through the layers of dreams and reality. With a gripping plot, stunning visuals, and a stellar cast led by Leonardo DiCaprio, this film challenges the audience to question the very nature of consciousness.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "boAaSMYmgO22",
      "metadata": {
        "id": "boAaSMYmgO22"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e9a54bf1-1aa8-4041-ae37-9ef27013283a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9a54bf1-1aa8-4041-ae37-9ef27013283a",
        "outputId": "1bfef668-0f2d-4dc9-ad67-cc9c866562de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
            "Original Text:\n",
            "Christopher Nolan’s Inception is a mind-bending journey through the layers of dreams and reality. With a gripping plot, stunning visuals, and a stellar cast led by Leonardo DiCaprio, this film challenges the audience to question the very nature of consciousness.\n",
            "\n",
            "TF-IDF Matrix:\n",
            "[[0.40824829 0.20412415 0.20412415 0.40824829 0.61237244 0.20412415\n",
            "  0.20412415 0.20412415 0.20412415 0.20412415]]\n",
            "\n",
            "Feature Names:\n",
            "['and' 'by' 'is' 'of' 'the' 'this' 'through' 'to' 'very' 'with']\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "print(\"\\nTF-IDF (Term Frequency-Inverse Document Frequency)\")\n",
        "corpus = [txt]\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"Original Text:\")\n",
        "print(text)\n",
        "print(\"\\nTF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"\\nFeature Names:\")\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "2NMrh3-jC3lK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NMrh3-jC3lK",
        "outputId": "9d460121-1b58-40f7-eb93-a0b08f7aa27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF (Term Frequency-Inverse Document Frequency)\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "print(\"\\nTF-IDF (Term Frequency-Inverse Document Frequency)\")\n",
        "corpus = [text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "bHPrz6GxC3nQ",
      "metadata": {
        "id": "bHPrz6GxC3nQ"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de86ea2-8087-4923-b7bc-eed781b83ca1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1de86ea2-8087-4923-b7bc-eed781b83ca1",
        "outputId": "0fa7fb7f-7360-49de-c005-086276c099aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.4 0.4 0.2 0.2 0.2 0.2 0.2 0.2\n",
            "  0.2]]\n",
            "['and' 'artificial' 'between' 'computers' 'field' 'focuses' 'humans'\n",
            " 'intelligence' 'interaction' 'is' 'language' 'natural' 'nlp' 'of' 'on'\n",
            " 'processing' 'that' 'the' 'using']\n"
          ]
        }
      ],
      "source": [
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "print(tfidf_matrix.toarray())\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGLhYhiuB1hU"
      },
      "source": [
        "# Task6:One-Hot Encoding: Encode the tokens using one-hot-encoding."
      ],
      "id": "gGLhYhiuB1hU"
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding\n",
        "def one_hot_encoding(text, vocab_size=None):\n",
        "    words = text.split()\n",
        "    if not vocab_size:\n",
        "        vocab_size = len(set(words))\n",
        "    word_to_index = {word: i for i, word in enumerate(set(words))}\n",
        "    one_hot_vector = [0] * vocab_size\n",
        "    for word in words:\n",
        "        index = word_to_index[word]\n",
        "        one_hot_vector[index] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "# Real-world example\n",
        "text = corpus[0]\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(text)\n",
        "\n",
        "# One-Hot Encoding\n",
        "one_hot_vector = one_hot_encoding(text)\n",
        "print(\"\\nOne-Hot Encoding:\")\n",
        "print(one_hot_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2PXiE_xDcVm",
        "outputId": "71b0a1a6-0ac6-4ed1-946f-a0d6ddbdeb2f"
      },
      "id": "s2PXiE_xDcVm",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Christopher Nolan’s Inception is a mind-bending journey through the layers of dreams and reality. With a gripping plot, stunning visuals, and a stellar cast led by Leonardo DiCaprio, this film challenges the audience to question the very nature of consciousness.\n",
            "\n",
            "One-Hot Encoding:\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M78kK_eL2eB"
      },
      "source": [
        "# Task7:Bag of Words: Create a bag of words representation of-  the text."
      ],
      "id": "9M78kK_eL2eB"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTwKaTlvNZ7z",
        "outputId": "0b99f13a-4234-4d54-c1da-61bf08041302"
      },
      "id": "zTwKaTlvNZ7z",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Dummy data\n",
        "corpus =[\n",
        "    \"Natural language processing is a field of artificial intelligence.\",\n",
        "    \"It involves the interaction between computers and humans using natural language.\",\n",
        "    \"NLP techniques are used in various applications like chatbots and language translation.\",\n",
        "    \"Word embeddings capture semantic relationships between words in a continuous vector space.\",\n",
        "\"Generative AI is a new branch of AI . \", \"It does all the heavy lifting that is done by nltk making it simpler. \",\"Langchain is one such framework\"]"
      ],
      "metadata": {
        "id": "JKpgJpyRNESb"
      },
      "id": "JKpgJpyRNESb",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words\n",
        "def bag_of_words(corpus):\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    return X.toarray(), vectorizer.get_feature_names_out()\n",
        "\n",
        "# Bag of Words\n",
        "bow_vector, feature_names = bag_of_words(corpus)\n",
        "print(\"\\nBag of Words:\")\n",
        "print(bow_vector)\n",
        "print(\"Feature Names:\", feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Qjr3nxMAcj",
        "outputId": "a4ac6639-e538-47bb-cd23-960553bee873"
      },
      "id": "p7Qjr3nxMAcj",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words:\n",
            "[[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0\n",
            "  1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
            "  0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1]\n",
            " [2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
            "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 2 0 0 1 0 1 0 0 0 1\n",
            "  0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
            "  0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]]\n",
            "Feature Names: ['ai' 'all' 'and' 'applications' 'are' 'artificial' 'between' 'branch'\n",
            " 'by' 'capture' 'chatbots' 'computers' 'continuous' 'does' 'done'\n",
            " 'embeddings' 'field' 'framework' 'generative' 'heavy' 'humans' 'in'\n",
            " 'intelligence' 'interaction' 'involves' 'is' 'it' 'langchain' 'language'\n",
            " 'lifting' 'like' 'making' 'natural' 'new' 'nlp' 'nltk' 'of' 'one'\n",
            " 'processing' 'relationships' 'semantic' 'simpler' 'space' 'such'\n",
            " 'techniques' 'that' 'the' 'translation' 'used' 'using' 'various' 'vector'\n",
            " 'word' 'words']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KttqLaS0Qfd3"
      },
      "source": [
        "# Task8:Unigram, Bigram, n-gram: Generate unigram, bigram, and n-gram representations of the text.(Unigram represents a single word, Bigram represents a pair of consecutive words, and N-gram represents a sequence of N words.)"
      ],
      "id": "KttqLaS0Qfd3"
    },
    {
      "cell_type": "code",
      "source": [
        "# N-gram\n",
        "def n_gram(text, n):\n",
        "    words = text.split()\n",
        "    ngrams=[]\n",
        "    for i in range(len(words)-n+1):\n",
        "        ngram = tuple(words[i:i+n])\n",
        "        ngrams.append(ngram)\n",
        "  #  ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
        "    return ngrams\n",
        "\n",
        "unigrams = n_gram(text, 1)\n",
        "bigrams = n_gram(text, 3)\n",
        "print(\"\\nUnigrams:\")\n",
        "print(unigrams)\n",
        "print(\"\\nBigrams:\")\n",
        "print(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQX1H3g6QsOX",
        "outputId": "0da417e8-7e70-4599-b68e-927b35878505"
      },
      "id": "pQX1H3g6QsOX",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unigrams:\n",
            "[('Christopher',), ('Nolan’s',), ('Inception',), ('is',), ('a',), ('mind-bending',), ('journey',), ('through',), ('the',), ('layers',), ('of',), ('dreams',), ('and',), ('reality.',), ('With',), ('a',), ('gripping',), ('plot,',), ('stunning',), ('visuals,',), ('and',), ('a',), ('stellar',), ('cast',), ('led',), ('by',), ('Leonardo',), ('DiCaprio,',), ('this',), ('film',), ('challenges',), ('the',), ('audience',), ('to',), ('question',), ('the',), ('very',), ('nature',), ('of',), ('consciousness.',)]\n",
            "\n",
            "Bigrams:\n",
            "[('Christopher', 'Nolan’s', 'Inception'), ('Nolan’s', 'Inception', 'is'), ('Inception', 'is', 'a'), ('is', 'a', 'mind-bending'), ('a', 'mind-bending', 'journey'), ('mind-bending', 'journey', 'through'), ('journey', 'through', 'the'), ('through', 'the', 'layers'), ('the', 'layers', 'of'), ('layers', 'of', 'dreams'), ('of', 'dreams', 'and'), ('dreams', 'and', 'reality.'), ('and', 'reality.', 'With'), ('reality.', 'With', 'a'), ('With', 'a', 'gripping'), ('a', 'gripping', 'plot,'), ('gripping', 'plot,', 'stunning'), ('plot,', 'stunning', 'visuals,'), ('stunning', 'visuals,', 'and'), ('visuals,', 'and', 'a'), ('and', 'a', 'stellar'), ('a', 'stellar', 'cast'), ('stellar', 'cast', 'led'), ('cast', 'led', 'by'), ('led', 'by', 'Leonardo'), ('by', 'Leonardo', 'DiCaprio,'), ('Leonardo', 'DiCaprio,', 'this'), ('DiCaprio,', 'this', 'film'), ('this', 'film', 'challenges'), ('film', 'challenges', 'the'), ('challenges', 'the', 'audience'), ('the', 'audience', 'to'), ('audience', 'to', 'question'), ('to', 'question', 'the'), ('question', 'the', 'very'), ('the', 'very', 'nature'), ('very', 'nature', 'of'), ('nature', 'of', 'consciousness.')]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}