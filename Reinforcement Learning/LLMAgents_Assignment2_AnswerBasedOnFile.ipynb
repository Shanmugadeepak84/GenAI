{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYADlt-gxIXk"
      },
      "outputs": [],
      "source": [
        "pip install -U langchain langchain-community langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using OpenAI\n",
        "import os\n",
        "from openai import OpenAI\n",
        "OPENAI_API_KEY=\"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\"\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "class GPTQuery:\n",
        "    def __init__(self, model=\"gpt-3.5-turbo\"):\n",
        "        self.client = OpenAI(api_key=\"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\")\n",
        "        self.model = model\n",
        "\n",
        "    def get_response(self, prompt, system_role=\"You are a helpful assistant.\"):\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_role},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# Create query object\n",
        "query = GPTQuery()\n",
        "\n",
        "# Read text file\n",
        "with open(\"/content/sample_data/AI_History.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text_data = f.read()\n",
        "\n",
        "# Now use get_response like you wanted\n",
        "qa = query.get_response(f\"Based on this text, answer: When is the Birth of Modern AI?\\n\\n{text_data}\")\n",
        "print(qa)\n"
      ],
      "metadata": {
        "id": "QvNRs_jK5O8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using hugging face free source\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "client = InferenceClient(model=\"mistralai/Mistral-7B-Instruct-v0.2\",token=\"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\")\n",
        "#Read file\n",
        "with open(\"/content/sample_data/AI_History.txt\",\"r\", encoding=\"utf-8\") as f:\n",
        "    text_data = f.read()\n",
        "\n",
        "#Ask a question based on the text\n",
        "question =f\"Based on this text, answer: What is the trend in 2011?\\n\\n{text_data}\"\n",
        "\n",
        "#Prompt\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant. Answer only based on the given text.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"TEXT:\\n{text_data}\\n\\nQUESTION: {question}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "#Call chat completion\n",
        "response = client.chat_completion(\n",
        "    messages,\n",
        "    max_tokens=300,\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "print(\"Answer:\", response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7by0-bk-g8v",
        "outputId": "cae7c4a5-01d9-4165-979a-70dd94040f4d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  In 2011, IBM's Watson won the quiz show Jeopardy!, demonstrating AI's ability to understand natural language and complex questions.\n"
          ]
        }
      ]
    }
  ]
}